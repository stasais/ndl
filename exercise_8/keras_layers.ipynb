{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22af6cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs directory cleared\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"logs\"):\n",
    "    shutil.rmtree(\"logs\")\n",
    "    print(\"Logs directory cleared\")\n",
    "else:\n",
    "    print(\"No logs directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d8d1a",
   "metadata": {},
   "source": [
    "# Introduction to Keras and Layertypes\n",
    "Previously you built a simple artificial neural net (ANN) with one hidden layer and sigmoid activation function. Today we will take a look at a few adaptations of such a basic net both in terms of NN architecture as well as layer types. We will still stay with Fully Connected Neural Networks for this first exercise!\n",
    "\n",
    "things to go through:\n",
    "- activation functions (issue with sigmoid -> ReLU, Leaky ReLU)\n",
    "- drop out\n",
    "- skip connections\n",
    "- deeper neural nets\n",
    "- potential issues of Fully Connected Neural Networks (Scaling?)\n",
    "- Keras things like functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad3308",
   "metadata": {},
   "source": [
    "## Setup things\n",
    "Make sure your environment has all the required packages available. Take care to have\n",
    "- keras (Read [This short guide](https://keras.io/getting_started/))\n",
    "- a backend of your choosing for Keras (I dont care which one you use but we will stay with Tensorflow for now)\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- tensorboard (optional)\n",
    "\n",
    "Feel free to use a package manager of your choice (avoid conda) or a premade environment in Azure.\n",
    "Also make sure you have the data files you need ready, I recommend putting them into a ./data/ subdir\n",
    "\n",
    "## Loading and preparing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a15775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14801, 31) (4934, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>...</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "      <th>dayinweek</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>0</td>\n",
       "      <td>24.79</td>\n",
       "      <td>38.79</td>\n",
       "      <td>23.70</td>\n",
       "      <td>37.933333</td>\n",
       "      <td>25.463333</td>\n",
       "      <td>37.966667</td>\n",
       "      <td>24.390000</td>\n",
       "      <td>37.40</td>\n",
       "      <td>22.60</td>\n",
       "      <td>...</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.55</td>\n",
       "      <td>21.479084</td>\n",
       "      <td>21.479084</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11652</th>\n",
       "      <td>0</td>\n",
       "      <td>22.39</td>\n",
       "      <td>38.50</td>\n",
       "      <td>22.60</td>\n",
       "      <td>36.626667</td>\n",
       "      <td>22.390000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>21.133333</td>\n",
       "      <td>37.20</td>\n",
       "      <td>19.70</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>21.739472</td>\n",
       "      <td>21.739472</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>18.39</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>43.326667</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>41.59</td>\n",
       "      <td>17.89</td>\n",
       "      <td>...</td>\n",
       "      <td>91.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.55</td>\n",
       "      <td>48.508109</td>\n",
       "      <td>48.508109</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lights     T1   RH_1     T2       RH_2         T3       RH_3  \\\n",
       "16885       0  24.79  38.79  23.70  37.933333  25.463333  37.966667   \n",
       "11652       0  22.39  38.50  22.60  36.626667  22.390000  37.900000   \n",
       "339         0  19.00  42.00  18.39  41.200000  20.000000  43.326667   \n",
       "\n",
       "              T4   RH_4     T5  ...  RH_out  Windspeed  Visibility  Tdewpoint  \\\n",
       "16885  24.390000  37.40  22.60  ...    73.5        1.0        40.0      10.55   \n",
       "11652  21.133333  37.20  19.70  ...    57.0        3.0        40.0       2.40   \n",
       "339    18.600000  41.59  17.89  ...    91.5        5.0        27.5       1.55   \n",
       "\n",
       "             rv1        rv2  dayinweek  month  hour  minutes  \n",
       "16885  21.479084  21.479084          5      5    23       10  \n",
       "11652  21.739472  21.739472          4      4    15        0  \n",
       "339    48.508109  48.508109          3      1     1       30  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"data/energydata_complete.csv\")\n",
    "\n",
    "# For timeseries such as this, are rows really independent?\n",
    "# Is there a separate approach to this problem? What patterns do we lose by treating the dataset like this?\n",
    "df['date_time'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['dayinweek'] = df['date_time'].dt.day_of_week\n",
    "df['month'] = df['date_time'].dt.month\n",
    "df['hour'] = df[\"date_time\"].dt.hour\n",
    "df['minutes'] = df['date_time'].dt.minute\n",
    "df.drop(columns=['date_time'], inplace=True)\n",
    "\n",
    "# how do we keep it random but reproducible?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[\"Appliances\",\"date\"]), df['Appliances'])\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "sd = StandardScaler()\n",
    "X_train_scaled = sd.fit_transform(X_train)\n",
    "X_test_scaled = sd.transform(X_test)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdaccb",
   "metadata": {},
   "source": [
    "## Vanishing Gradient Problem with Sigmoid\n",
    "\n",
    "Sigmoid's derivative ranges from 0 to 0.25 (max at the middle).\n",
    "\n",
    "During backpropagation, gradients multiply layer-by-layer: 0.25 × 0.25 × 0.25...\n",
    "\n",
    "**Result:** Gradients shrink exponentially in deeper networks → early layers barely learn. **Deeper Networks fail with sigmoid**\n",
    "\n",
    "**Solution:** Use e.g. ReLU (derivative = 1 for positive inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f07bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras 3.12.0 with backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "print(f\"Using Keras {keras.__version__} with backend: {keras.backend.backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0b390b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from utils import train_model,eval_model\n",
    "\n",
    "model_sigmoid = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(512, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(256, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(128, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(64, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(32, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, activation=None)\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model_sigmoid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0632066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_relu = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=None)\n",
    "])\n",
    "\n",
    "model_relu.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572dccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_leaky_relu = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_scaled.shape[1],)), #\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    keras.layers.Dense(64),\n",
    "    keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    keras.layers.Dense(32),\n",
    "    keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    keras.layers.Dense(1, activation=None)\n",
    "])\n",
    "\n",
    "model_leaky_relu.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model_leaky_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e58eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 19625.3613 - mae: 93.3940 - val_loss: 17909.5000 - val_mae: 89.4550\n",
      "Epoch 2/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18441.6504 - mae: 86.8085 - val_loss: 16780.2520 - val_mae: 82.9067\n",
      "Epoch 3/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17292.9902 - mae: 79.9503 - val_loss: 15715.0938 - val_mae: 76.2779\n",
      "Epoch 4/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16304.5342 - mae: 73.7243 - val_loss: 14751.9023 - val_mae: 69.9041\n",
      "Epoch 5/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15368.1914 - mae: 67.3677 - val_loss: 13906.4219 - val_mae: 64.1155\n",
      "Epoch 6/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14588.4463 - mae: 61.9379 - val_loss: 13192.2793 - val_mae: 58.9683\n",
      "Epoch 7/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13920.4639 - mae: 57.5383 - val_loss: 12576.1963 - val_mae: 55.0257\n",
      "Epoch 8/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13345.6191 - mae: 53.8229 - val_loss: 12050.7070 - val_mae: 52.0362\n",
      "Epoch 9/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12851.4375 - mae: 51.9814 - val_loss: 11600.0166 - val_mae: 50.7428\n",
      "Epoch 10/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12430.3984 - mae: 50.8048 - val_loss: 11215.7881 - val_mae: 50.0928\n",
      "Epoch 11/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12077.6055 - mae: 50.8522 - val_loss: 10901.6787 - val_mae: 50.4610\n",
      "Epoch 12/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11786.4414 - mae: 51.1927 - val_loss: 10640.7432 - val_mae: 50.9533\n",
      "Epoch 13/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11551.7285 - mae: 52.0183 - val_loss: 10437.9590 - val_mae: 51.9002\n",
      "Epoch 14/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11366.3916 - mae: 52.9643 - val_loss: 10276.6504 - val_mae: 52.7936\n",
      "Epoch 15/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11222.9688 - mae: 53.9087 - val_loss: 10155.5098 - val_mae: 53.8765\n",
      "Epoch 16/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11104.3115 - mae: 55.2456 - val_loss: 10050.9150 - val_mae: 55.2200\n",
      "Epoch 17/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11021.7529 - mae: 56.3830 - val_loss: 9990.6357 - val_mae: 56.2372\n",
      "Epoch 18/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10971.4414 - mae: 57.4186 - val_loss: 9953.3398 - val_mae: 57.2007\n",
      "Epoch 19/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10940.9551 - mae: 58.3557 - val_loss: 9931.6113 - val_mae: 58.0607\n",
      "Epoch 20/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10922.6172 - mae: 59.0569 - val_loss: 9919.0117 - val_mae: 58.7602\n",
      "Epoch 21/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10912.1201 - mae: 59.6827 - val_loss: 9912.3838 - val_mae: 59.3014\n",
      "Epoch 22/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10906.6836 - mae: 60.1675 - val_loss: 9909.5713 - val_mae: 59.6485\n",
      "Epoch 23/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10904.0557 - mae: 60.5427 - val_loss: 9908.1289 - val_mae: 59.9254\n",
      "Epoch 24/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10902.7256 - mae: 60.7069 - val_loss: 9907.4863 - val_mae: 60.1490\n",
      "Epoch 25/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.9551 - mae: 60.9216 - val_loss: 9907.3555 - val_mae: 60.2395\n",
      "Epoch 26/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.6611 - mae: 60.9926 - val_loss: 9907.3027 - val_mae: 60.3616\n",
      "Epoch 27/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.5078 - mae: 61.0900 - val_loss: 9907.3320 - val_mae: 60.4274\n",
      "Epoch 28/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3184 - mae: 61.2347 - val_loss: 9907.3711 - val_mae: 60.4687\n",
      "Epoch 29/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3945 - mae: 61.2613 - val_loss: 9907.3711 - val_mae: 60.4700\n",
      "Epoch 30/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4561 - mae: 61.1699 - val_loss: 9907.3779 - val_mae: 60.4751\n",
      "Epoch 31/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4824 - mae: 61.2398 - val_loss: 9907.4219 - val_mae: 60.5081\n",
      "Epoch 32/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3232 - mae: 61.2650 - val_loss: 9907.4072 - val_mae: 60.4993\n",
      "Epoch 33/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4619 - mae: 61.2954 - val_loss: 9907.4717 - val_mae: 60.5382\n",
      "Epoch 34/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3398 - mae: 61.2247 - val_loss: 9907.4023 - val_mae: 60.4936\n",
      "Epoch 35/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4688 - mae: 61.2089 - val_loss: 9907.5146 - val_mae: 60.5610\n",
      "Epoch 36/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.5342 - mae: 61.3500 - val_loss: 9907.4814 - val_mae: 60.5425\n",
      "Epoch 37/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3418 - mae: 61.2210 - val_loss: 9907.4795 - val_mae: 60.5426\n",
      "Epoch 38/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4023 - mae: 61.2205 - val_loss: 9907.5293 - val_mae: 60.5676\n",
      "Epoch 39/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3008 - mae: 61.2241 - val_loss: 9907.5410 - val_mae: 60.5730\n",
      "Epoch 40/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4658 - mae: 61.2723 - val_loss: 9907.4766 - val_mae: 60.5404\n",
      "Epoch 41/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.2646 - mae: 61.2146 - val_loss: 9907.6016 - val_mae: 60.6005\n",
      "Epoch 42/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3125 - mae: 61.3028 - val_loss: 9907.5996 - val_mae: 60.6004\n",
      "Epoch 43/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.4004 - mae: 61.3448 - val_loss: 9907.4990 - val_mae: 60.5527\n",
      "Epoch 44/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10901.3184 - mae: 61.2860 - val_loss: 9907.5186 - val_mae: 60.5695\n",
      "Epoch 45/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10365.9814 - mae: 51.2803 - val_loss: 9241.6904 - val_mae: 50.2403\n",
      "Epoch 46/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10127.8574 - mae: 50.9445 - val_loss: 9117.6846 - val_mae: 50.7825\n",
      "Epoch 47/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10035.7520 - mae: 51.5520 - val_loss: 9101.3350 - val_mae: 50.8980\n",
      "Epoch 48/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9986.0430 - mae: 52.2590 - val_loss: 9007.4473 - val_mae: 51.5898\n",
      "Epoch 49/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9961.6270 - mae: 52.9676 - val_loss: 9037.3086 - val_mae: 52.2878\n",
      "Epoch 50/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9925.0508 - mae: 53.2169 - val_loss: 9029.6201 - val_mae: 52.2896\n",
      "Epoch 1/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10121.5254 - mae: 55.9895 - val_loss: 8451.9062 - val_mae: 50.4234\n",
      "Epoch 2/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8855.5078 - mae: 51.9032 - val_loss: 7923.5996 - val_mae: 45.8011\n",
      "Epoch 3/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8463.1104 - mae: 50.5936 - val_loss: 7629.9575 - val_mae: 50.4938\n",
      "Epoch 4/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8158.6367 - mae: 48.3939 - val_loss: 7774.3628 - val_mae: 51.2163\n",
      "Epoch 5/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7919.4629 - mae: 47.3955 - val_loss: 7370.6943 - val_mae: 43.3815\n",
      "Epoch 6/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7652.4458 - mae: 46.1005 - val_loss: 7133.0259 - val_mae: 44.7370\n",
      "Epoch 7/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7475.9810 - mae: 45.8248 - val_loss: 7499.8120 - val_mae: 48.2649\n",
      "Epoch 8/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7204.4946 - mae: 44.4982 - val_loss: 7462.8545 - val_mae: 47.3369\n",
      "Epoch 9/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7032.4751 - mae: 44.0299 - val_loss: 7070.5957 - val_mae: 43.4153\n",
      "Epoch 10/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6863.6670 - mae: 42.6788 - val_loss: 7460.3599 - val_mae: 51.5860\n",
      "Epoch 11/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6575.6299 - mae: 42.4666 - val_loss: 6867.4443 - val_mae: 44.8550\n",
      "Epoch 12/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6467.3013 - mae: 41.6093 - val_loss: 7235.2422 - val_mae: 47.1596\n",
      "Epoch 13/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6223.1201 - mae: 41.1111 - val_loss: 6836.3730 - val_mae: 40.6876\n",
      "Epoch 14/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5959.7832 - mae: 39.9434 - val_loss: 6973.9702 - val_mae: 45.3412\n",
      "Epoch 15/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5692.7920 - mae: 39.2040 - val_loss: 6907.7900 - val_mae: 42.1701\n",
      "Epoch 16/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5654.7158 - mae: 38.9955 - val_loss: 6623.4028 - val_mae: 39.8910\n",
      "Epoch 17/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5335.8833 - mae: 37.8839 - val_loss: 7163.1328 - val_mae: 42.2014\n",
      "Epoch 18/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5261.5269 - mae: 37.8040 - val_loss: 6661.6172 - val_mae: 44.1867\n",
      "Epoch 19/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4923.8081 - mae: 36.6182 - val_loss: 6879.4854 - val_mae: 40.7702\n",
      "Epoch 20/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4858.5215 - mae: 36.2587 - val_loss: 6792.8594 - val_mae: 41.1892\n",
      "Epoch 21/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4740.7534 - mae: 35.7625 - val_loss: 6864.3257 - val_mae: 42.7071\n",
      "Epoch 22/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4533.2661 - mae: 35.2800 - val_loss: 7016.1265 - val_mae: 40.8082\n",
      "Epoch 23/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4312.0186 - mae: 34.4350 - val_loss: 7836.1411 - val_mae: 43.6698\n",
      "Epoch 24/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4310.9604 - mae: 34.3050 - val_loss: 7240.0161 - val_mae: 43.1419\n",
      "Epoch 25/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3968.1909 - mae: 33.2711 - val_loss: 7095.6807 - val_mae: 41.9352\n",
      "Epoch 26/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3928.7561 - mae: 33.0854 - val_loss: 7307.9595 - val_mae: 43.9193\n",
      "Epoch 27/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3740.5649 - mae: 32.4337 - val_loss: 7276.0972 - val_mae: 41.0892\n",
      "Epoch 28/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3581.9023 - mae: 31.6968 - val_loss: 6989.9731 - val_mae: 39.1442\n",
      "Epoch 29/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3559.3679 - mae: 31.4122 - val_loss: 7156.6099 - val_mae: 40.0681\n",
      "Epoch 30/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3341.1768 - mae: 30.6917 - val_loss: 7611.4092 - val_mae: 43.6363\n",
      "Epoch 31/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3203.1936 - mae: 29.9591 - val_loss: 7320.6978 - val_mae: 43.2589\n",
      "Epoch 32/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3162.5305 - mae: 29.9520 - val_loss: 7616.8989 - val_mae: 41.9114\n",
      "Epoch 33/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3028.1646 - mae: 29.1549 - val_loss: 7196.9443 - val_mae: 41.9147\n",
      "Epoch 34/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2918.4834 - mae: 28.7997 - val_loss: 7083.4878 - val_mae: 41.0315\n",
      "Epoch 35/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2850.7771 - mae: 28.3702 - val_loss: 7026.8564 - val_mae: 40.8523\n",
      "Epoch 36/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2768.6565 - mae: 27.8956 - val_loss: 7009.5820 - val_mae: 40.8013\n",
      "Epoch 37/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2603.1213 - mae: 27.2927 - val_loss: 7015.9150 - val_mae: 41.2367\n",
      "Epoch 38/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2477.0723 - mae: 26.5456 - val_loss: 7057.1953 - val_mae: 41.1748\n",
      "Epoch 39/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2461.5115 - mae: 26.4427 - val_loss: 7213.2896 - val_mae: 42.8566\n",
      "Epoch 40/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2327.3008 - mae: 25.5510 - val_loss: 7263.4678 - val_mae: 40.7955\n",
      "Epoch 41/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2503.3755 - mae: 26.3500 - val_loss: 6982.7847 - val_mae: 41.3803\n",
      "Epoch 42/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2148.9692 - mae: 24.8885 - val_loss: 7343.8662 - val_mae: 42.7998\n",
      "Epoch 43/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2044.7144 - mae: 24.3944 - val_loss: 7178.4668 - val_mae: 39.8679\n",
      "Epoch 44/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1952.5349 - mae: 23.9663 - val_loss: 7396.2202 - val_mae: 42.5881\n",
      "Epoch 45/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1923.2433 - mae: 23.5490 - val_loss: 7427.7002 - val_mae: 40.9408\n",
      "Epoch 46/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1931.7659 - mae: 23.8503 - val_loss: 7662.6538 - val_mae: 41.9828\n",
      "Epoch 47/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1965.4128 - mae: 23.9104 - val_loss: 7176.4780 - val_mae: 41.1753\n",
      "Epoch 48/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2010.4847 - mae: 23.7351 - val_loss: 7152.2866 - val_mae: 39.9991\n",
      "Epoch 49/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1694.1787 - mae: 22.5149 - val_loss: 7463.3218 - val_mae: 41.1930\n",
      "Epoch 50/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1628.2628 - mae: 22.1483 - val_loss: 7544.3159 - val_mae: 42.2514\n",
      "Epoch 1/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10068.9971 - mae: 56.2691 - val_loss: 8597.8633 - val_mae: 58.3776\n",
      "Epoch 2/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8855.6504 - mae: 51.8997 - val_loss: 7841.3535 - val_mae: 47.4546\n",
      "Epoch 3/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8438.3975 - mae: 50.2667 - val_loss: 7665.6177 - val_mae: 51.2360\n",
      "Epoch 4/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8138.9336 - mae: 49.1567 - val_loss: 7529.2529 - val_mae: 46.6275\n",
      "Epoch 5/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7825.5547 - mae: 47.3412 - val_loss: 8009.0542 - val_mae: 55.1547\n",
      "Epoch 6/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7671.3594 - mae: 46.9908 - val_loss: 7627.4346 - val_mae: 49.9063\n",
      "Epoch 7/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7398.0015 - mae: 45.8530 - val_loss: 7146.8867 - val_mae: 42.5565\n",
      "Epoch 8/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7229.6426 - mae: 45.2845 - val_loss: 6936.4727 - val_mae: 43.5571\n",
      "Epoch 9/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7064.1392 - mae: 44.4920 - val_loss: 7059.1489 - val_mae: 46.2978\n",
      "Epoch 10/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6759.7197 - mae: 43.1749 - val_loss: 6874.7881 - val_mae: 45.0041\n",
      "Epoch 11/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6686.7056 - mae: 42.8499 - val_loss: 7232.2256 - val_mae: 48.7457\n",
      "Epoch 12/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6234.2061 - mae: 41.9238 - val_loss: 7088.5078 - val_mae: 42.6878\n",
      "Epoch 13/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6205.2202 - mae: 40.9702 - val_loss: 6799.3555 - val_mae: 46.0288\n",
      "Epoch 14/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6090.6460 - mae: 40.7652 - val_loss: 7118.0352 - val_mae: 40.0723\n",
      "Epoch 15/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5849.8115 - mae: 39.8950 - val_loss: 6980.7026 - val_mae: 41.9103\n",
      "Epoch 16/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5760.0171 - mae: 39.5435 - val_loss: 6983.5918 - val_mae: 40.3159\n",
      "Epoch 17/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5450.8115 - mae: 38.3706 - val_loss: 7159.6523 - val_mae: 47.3549\n",
      "Epoch 18/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5203.1929 - mae: 37.3128 - val_loss: 6690.3101 - val_mae: 41.0886\n",
      "Epoch 19/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5131.6973 - mae: 37.4435 - val_loss: 6941.4385 - val_mae: 40.4268\n",
      "Epoch 20/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4859.2080 - mae: 36.2303 - val_loss: 7264.5142 - val_mae: 42.5807\n",
      "Epoch 21/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4748.8774 - mae: 35.8993 - val_loss: 6975.6831 - val_mae: 44.4868\n",
      "Epoch 22/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4640.3145 - mae: 35.2451 - val_loss: 6925.3589 - val_mae: 43.5154\n",
      "Epoch 23/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4305.9546 - mae: 34.6819 - val_loss: 6811.7080 - val_mae: 40.6527\n",
      "Epoch 24/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4323.9648 - mae: 34.5762 - val_loss: 6944.6592 - val_mae: 40.7129\n",
      "Epoch 25/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3970.9807 - mae: 33.2294 - val_loss: 7155.7095 - val_mae: 42.2531\n",
      "Epoch 26/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3927.2598 - mae: 32.7312 - val_loss: 7075.6338 - val_mae: 40.4481\n",
      "Epoch 27/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3756.4082 - mae: 32.1040 - val_loss: 7998.9219 - val_mae: 45.9740\n",
      "Epoch 28/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3610.8079 - mae: 31.6615 - val_loss: 7399.4292 - val_mae: 43.5061\n",
      "Epoch 29/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3550.5554 - mae: 31.4514 - val_loss: 7524.2217 - val_mae: 43.1716\n",
      "Epoch 30/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3379.7781 - mae: 30.6715 - val_loss: 7003.5679 - val_mae: 41.6440\n",
      "Epoch 31/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3085.7200 - mae: 29.3380 - val_loss: 6904.1484 - val_mae: 40.7564\n",
      "Epoch 32/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3021.5315 - mae: 29.1553 - val_loss: 6968.3667 - val_mae: 41.8489\n",
      "Epoch 33/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3000.5811 - mae: 29.0050 - val_loss: 7367.9414 - val_mae: 42.7958\n",
      "Epoch 34/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2920.0781 - mae: 28.3971 - val_loss: 7520.1943 - val_mae: 42.7778\n",
      "Epoch 35/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2760.7537 - mae: 27.8351 - val_loss: 7513.1011 - val_mae: 41.3276\n",
      "Epoch 36/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2601.6648 - mae: 27.1026 - val_loss: 7830.7241 - val_mae: 43.7506\n",
      "Epoch 37/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2481.4919 - mae: 26.5211 - val_loss: 7825.1118 - val_mae: 44.4118\n",
      "Epoch 38/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2502.4844 - mae: 26.7222 - val_loss: 7510.6733 - val_mae: 41.7716\n",
      "Epoch 39/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2435.9092 - mae: 26.0801 - val_loss: 7573.1289 - val_mae: 44.8173\n",
      "Epoch 40/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2091.8555 - mae: 24.5832 - val_loss: 7895.8726 - val_mae: 41.3643\n",
      "Epoch 41/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2212.5601 - mae: 25.1540 - val_loss: 7526.2627 - val_mae: 41.7036\n",
      "Epoch 42/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2082.3704 - mae: 24.3285 - val_loss: 7298.6733 - val_mae: 39.7873\n",
      "Epoch 43/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2159.6416 - mae: 24.6034 - val_loss: 7352.3613 - val_mae: 40.3117\n",
      "Epoch 44/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2010.2275 - mae: 23.9476 - val_loss: 7995.1953 - val_mae: 42.8646\n",
      "Epoch 45/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1769.0479 - mae: 22.6562 - val_loss: 7314.9590 - val_mae: 40.7163\n",
      "Epoch 46/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1799.6980 - mae: 22.5443 - val_loss: 8090.7295 - val_mae: 45.7425\n",
      "Epoch 47/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1794.1708 - mae: 22.9622 - val_loss: 7642.2803 - val_mae: 42.5199\n",
      "Epoch 48/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1719.3351 - mae: 22.3543 - val_loss: 7531.5049 - val_mae: 42.4035\n",
      "Epoch 49/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1649.2594 - mae: 22.0526 - val_loss: 7252.1216 - val_mae: 40.1578\n",
      "Epoch 50/50\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1606.4244 - mae: 21.6532 - val_loss: 7252.5952 - val_mae: 41.6785\n"
     ]
    }
   ],
   "source": [
    "history_sigmoid = train_model(model_sigmoid, X_train_scaled, y_train, \"sigmoid_deep\")\n",
    "history_relu = train_model(model_relu, X_train_scaled, y_train, \"relu_deep\")\n",
    "history_leaky_relu = train_model(model_leaky_relu, X_train_scaled, y_train, \"leaky_relu_deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd776c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "  Sigmoid Deep Network - Test Results\n",
      "==================================================\n",
      "  Test Loss (MSE): 8,939.87\n",
      "  Test MAE:        51.38\n",
      "  R² Score:        0.0999 (9.99% variance explained)\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "  ReLU Deep Network - Test Results\n",
      "==================================================\n",
      "  Test Loss (MSE): 6,930.60\n",
      "  Test MAE:        40.06\n",
      "  R² Score:        0.3022 (30.22% variance explained)\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "  Leaky ReLU Deep Network - Test Results\n",
      "==================================================\n",
      "  Test Loss (MSE): 7,016.26\n",
      "  Test MAE:        40.92\n",
      "  R² Score:        0.2935 (29.35% variance explained)\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7016.25537109375, 40.91570281982422, 0.2935430407524109)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval on test set\n",
    "from utils import eval_model\n",
    "\n",
    "eval_model(model_sigmoid, X_test_scaled, y_test, \"Sigmoid Deep Network\")\n",
    "eval_model(model_relu, X_test_scaled, y_test, \"ReLU Deep Network\")\n",
    "eval_model(model_leaky_relu, X_test_scaled, y_test, \"Leaky ReLU Deep Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000ec8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f7a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71722889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
