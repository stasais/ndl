{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ed5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Clean up previous runs\n",
    "if os.path.exists(\"kt_hyperband\"):\n",
    "    shutil.rmtree(\"kt_hyperband\")\n",
    "if os.path.exists(\"kt_random\"):\n",
    "    shutil.rmtree(\"kt_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71c91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (48000, 64), X_val: (12000, 64), X_test: (10000, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data (same as Exercise 1)\n",
    "sym_dim = 8\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "X_train_full = X_train_full.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "X_test = X_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "\n",
    "X_train_full = resize(X_train_full.reshape(-1, 28, 28), (len(X_train_full), sym_dim, sym_dim)).reshape(-1, sym_dim*sym_dim).astype(\"float32\")\n",
    "X_test = resize(X_test.reshape(-1, 28, 28), (len(X_test), sym_dim, sym_dim)).reshape(-1, sym_dim*sym_dim).astype(\"float32\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5029285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model builder for Keras Tuner\n",
    "# Same search space as Exercise 1\n",
    "\n",
    "def build_model(hp):\n",
    "    # Number of layers (1-4)\n",
    "    num_layers = hp.Int(\"num_layers\", min_value=1, max_value=4)\n",
    "    \n",
    "    # Dropout rate (0.0 - 0.4)\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.0, max_value=0.4)\n",
    "    \n",
    "    # Learning rate (1e-4 to 1e-2, log scale)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    \n",
    "    # Optimizer choice\n",
    "    optimizer_name = hp.Choice(\"optimizer\", values=[\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    \n",
    "    # Batch size is handled in tuner.search(), not here\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.layers.Input(shape=(sym_dim * sym_dim,))\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        # Units per layer (64, 128, 256, 512)\n",
    "        units = hp.Choice(f\"units_{i}\", values=[64, 128, 256, 512])\n",
    "        x = keras.layers.Dense(units)(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Select optimizer\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b407f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767199385.296251  300784 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperband search space:\n",
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': None, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'rmsprop'], 'ordered': False}\n",
      "units_0 (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256, 512], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# Hyperband tuner\n",
    "hyperband_tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    factor=3,  # Reduction factor for successive halving\n",
    "    hyperband_iterations=1,\n",
    "    directory=\"kt_hyperband\",\n",
    "    project_name=\"fashion_mnist\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(\"Hyperband search space:\")\n",
    "hyperband_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd97a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 19s]\n",
      "val_accuracy: 0.7068333625793457\n",
      "\n",
      "Best val_accuracy So Far: 0.8730833530426025\n",
      "Total elapsed time: 00h 05m 34s\n",
      "\n",
      "Hyperband completed in 333.8 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run Hyperband search\n",
    "import time\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "start_time = time.time()\n",
    "hyperband_tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,  # Fixed batch size for fair comparison\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "hyperband_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nHyperband completed in {hyperband_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87eabd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (Hyperband):\n",
      "  num_layers: 3\n",
      "  dropout_rate: 0.142\n",
      "  learning_rate: 0.000358\n",
      "  optimizer: rmsprop\n",
      "  units_0: 64\n",
      "  units_1: 256\n",
      "  units_2: 512\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters from Hyperband\n",
    "best_hps = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters (Hyperband):\")\n",
    "print(f\"  num_layers: {best_hps.get('num_layers')}\")\n",
    "print(f\"  dropout_rate: {best_hps.get('dropout_rate'):.3f}\")\n",
    "print(f\"  learning_rate: {best_hps.get('learning_rate'):.6f}\")\n",
    "print(f\"  optimizer: {best_hps.get('optimizer')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"  units_{i}: {best_hps.get(f'units_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6aeba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 22s]\n",
      "val_accuracy: 0.7699999809265137\n",
      "\n",
      "Best val_accuracy So Far: 0.8845833539962769\n",
      "Total elapsed time: 00h 10m 24s\n",
      "\n",
      "Random search completed in 624.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random search for comparison (same budget)\n",
    "random_tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=30,  # Similar number of trials as Hyperband\n",
    "    directory=\"kt_random\",\n",
    "    project_name=\"fashion_mnist\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nRandom search completed in {random_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780a90ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (Random Search):\n",
      "  num_layers: 3\n",
      "  dropout_rate: 0.254\n",
      "  learning_rate: 0.000408\n",
      "  optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "best_hps_random = random_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters (Random Search):\")\n",
    "print(f\"  num_layers: {best_hps_random.get('num_layers')}\")\n",
    "print(f\"  dropout_rate: {best_hps_random.get('dropout_rate'):.3f}\")\n",
    "print(f\"  learning_rate: {best_hps_random.get('learning_rate'):.6f}\")\n",
    "print(f\"  optimizer: {best_hps_random.get('optimizer')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c92be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stas/my_git/ndl/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2025-12-31 17:59:05.942334: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_51', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "COMPARISON SUMMARY\n",
      "==================================================\n",
      "Hyperband:     test acc = 0.8588, time = 333.8s\n",
      "Random Search: test acc = 0.8765, time = 624.0s\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best models on test set\n",
    "best_model_hb = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "best_model_rs = random_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "_, acc_hb = best_model_hb.evaluate(X_test, y_test, verbose=0)\n",
    "_, acc_rs = best_model_rs.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Hyperband:     test acc = {acc_hb:.4f}, time = {hyperband_time:.1f}s\")\n",
    "print(f\"Random Search: test acc = {acc_rs:.4f}, time = {random_time:.1f}s\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f32b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecturenotes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
